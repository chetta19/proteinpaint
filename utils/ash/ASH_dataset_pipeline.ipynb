{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. pan-ALL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 pan-ALL snvindels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'liftover'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mliftover\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_lifter\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#liftover\u001b[39;00m\n\u001b[1;32m     12\u001b[0m converter \u001b[38;5;241m=\u001b[39m get_lifter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhg19\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhg38\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'liftover'"
     ]
    }
   ],
   "source": [
    "#generate a table for vcf generation \n",
    "#input is snvindels from PAN-ALL paper supplimentary table. file name: \"snvindel\"\n",
    "#output is a table with the following columns\n",
    "#sample_name     chr     pos     ref     alt     wgstumoralt     wgstumorref     wgsnoralt       wgsnorref       westumoralt     westumorref     wesnoralt       wesnorref       dna_assay\n",
    "#require the python package called liftover\n",
    "\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "from liftover import get_lifter\n",
    "\n",
    "#liftover\n",
    "converter = get_lifter('hg19','hg38')\n",
    "\n",
    "HG19FastFile = '/research/rgs01/resgen/legacy/gb_customTracks/tp/genomes/hg19.gz'\n",
    "\n",
    "#indel coordinate correction\n",
    "def GETREFALT(chro,ref,alt,pos,fa):\n",
    "        ref = ref.replace('-','')\n",
    "        alt = alt.replace('-','')\n",
    "        p = str(int(pos) - 1)\n",
    "        chro = chro if chro.startswith('chr') else 'chr'+chro\n",
    "        AddBase = list(os.popen('samtools faidx '+fa+' '+chro+':'+p+'-'+p))[1].strip().upper()\n",
    "        return AddBase+ref,AddBase+alt,p\n",
    "#hg38 coordinate convertion\n",
    "def COVHG38(orgchr,liftoverout):\n",
    "    pos = ''\n",
    "    for e in liftoverout:\n",
    "        hg38chr,hg38pos,hg38std = e\n",
    "        hg38chr = hg38chr[3:] if hg38chr[:3].lower() == 'chr' else hg38chr\n",
    "        if hg38chr == orgchr:\n",
    "            pos = str(hg38pos)\n",
    "    return pos\n",
    "    \n",
    "\n",
    "#with the following columns\n",
    "#sample_name     chr     pos     ref     alt     wgstumoralt     wgstumorref     wgsnoralt       wgsnorref       westumoralt     westumorref     wesnoralt       wesnorref       dna_assay\n",
    "fh = open('snvindel')\n",
    "out = open('panallsnvindel','w')\n",
    "out.write('\\t'.join(['sample_name','chr','pos','ref','alt','wgstumoralt','wgstumorref','wgsnoralt','wgsnorref','westumoralt','westumorref','wesnoralt','wesnorref','dna_assay'])+'\\n')\n",
    "for line in fh:\n",
    "    l = line.strip().split('\\t')\n",
    "    chrom = l[4]\n",
    "    chrom = chrom[3:] if chrom[:3].lower() == 'chr' else chrom\n",
    "    pos = l[5]\n",
    "    ref = l[6].replace('-','').strip()\n",
    "    alt = l[7].replace('-','').strip()\n",
    "    if not ref or not alt:\n",
    "        ref,alt,pos = indelcor.GETREFALT(chrom,ref,alt,pos,fasta)\n",
    "    hg38Cor = converter[chrom][int(pos)]\n",
    "    pos = COVHG38(chrom,hg38Cor)\n",
    "    if not pos:\n",
    "        continue\n",
    "    OUTL = [l[1],chrom,pos,ref,alt]\n",
    "    ASSAY = ''\n",
    "    #WGS read count\n",
    "    if re.match(\"\\d+$\",l[15]):\n",
    "        OUTL.append(l[15])\n",
    "        OUTL.append(str(int(l[16])-int(l[15])))\n",
    "        if re.match(\"\\d+$\",l[17]):\n",
    "            OUTL.append(l[17])\n",
    "            OUTL.append(str(int(l[18])-int(l[17])))\n",
    "        else:\n",
    "            OUTL.extend(['']*2)\n",
    "        ASSAY = 'WGS'\n",
    "    else:\n",
    "        OUTL.extend(['']*4)\n",
    "    \n",
    "    if re.match(\"\\d+$\",l[19]):\n",
    "        OUTL.append(l[19])\n",
    "        OUTL.append(str(int(l[20])-int(l[19])))\n",
    "        if re.match(\"\\d+$\",l[21]):\n",
    "            OUTL.append(l[21])\n",
    "            OUTL.append(str(int(l[22])-int(l[21])))\n",
    "        else:\n",
    "             OUTL.extend(['']*2)\n",
    "        if not ASSAY:\n",
    "            ASSAY = 'WES'\n",
    "    else:\n",
    "        OUTL.extend(['']*4)\n",
    "    OUTL.append(ASSAY)\n",
    "    out.write('\\t'.join(OUTL)+'\\n')\n",
    "fh.close()\n",
    "out.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions used to generate vcf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting snvindel.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile snvindel.py \n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "#generate SNVindel data store file for generating vcf file or combining of multiple file\n",
    "#infile: input file tab delimited\n",
    "#outfile: output file\n",
    "#return all samples in input file\n",
    "#optattr: optional attribute such as pmid, vorigin...\n",
    "def GENSNVINDEL(infile,outfile,optattr=[]):\n",
    "        fh = open(infile)\n",
    "        SNVINDEL = {}\n",
    "        HEAD = fh.readline().strip().split('\\t')\n",
    "        samidx = HEAD.index('sample_name')\n",
    "        sample = set()\n",
    "        chridx = HEAD.index('chr')\n",
    "        posidx = HEAD.index('pos')\n",
    "        refidx = HEAD.index('ref')\n",
    "        altidx = HEAD.index('alt')\n",
    "        rck = ['wgstumoralt','wgstumorref','wgsnoralt','wgsnorref','westumoralt','westumorref','wesnoralt','wesnorref','rnatumoralt','rnatumorref']\n",
    "        rckidx = {x:HEAD.index(x) for x in rck if x in HEAD}\n",
    "        rckused = list(rckidx.keys())\n",
    "        if optattr:\n",
    "            optattridx = {x.lower():HEAD.index(x) for x in optattr if x in HEAD}\n",
    "        for line in fh:\n",
    "            L = line.replace('\\n','').split('\\t')\n",
    "            sample.add(L[samidx])\n",
    "            chron,pos,ref,alt = [L[x] for x in [chridx,posidx,refidx,altidx]]\n",
    "            rcv = [L[rckidx[x]] for x in rckused]\n",
    "            readic = dict(zip(rckused,rcv))\n",
    "            ID,JS = PARSNVINDEL(genomefa,'',[chron,pos,ref,alt],readic)\n",
    "            if optattr:\n",
    "                for attr in optattr:\n",
    "                    JS[attr.lower()] = L[optattridx[attr.lower()]]\n",
    "            if ID not in SNVINDEL:\n",
    "                SNVINDEL[ID] = {L[samidx]:JS}\n",
    "            else:\n",
    "                SNVINDEL[ID].update({L[samidx]:JS})\n",
    "        fh.close()\n",
    "        snvout = open(outfile,'w')\n",
    "        for ID in SNVINDEL:\n",
    "            snvout.write('\\t'.join([ID,json.dumps(SNVINDEL[ID])])+'\\n')\n",
    "        snvout.close()\n",
    "        return sample\n",
    "\n",
    "# vtype could be somatic or germline\n",
    "#the parameters snvindel a list include chromsome, position, reference allele and alternative allele\n",
    "#will remove '-' from reference or alternative allele\n",
    "#retrive nucleotide and coordinate before indel\n",
    "#readcount is a dictionary including any of following keys:\n",
    "#WGS:   wgstumoralt,wgstumorref,wgsnoralt,wgsnorref,\n",
    "#CGI:   cgitumoralt,cgitumorref,cginoralt,cginorref,\n",
    "#WES:   westumoralt,westumorref,wesnoralt,wesnorref,\n",
    "#validation:    cctumoralt,cctumorref,ccnoralt,ccnorref,\n",
    "#RNA:   rnatumoralt,rnatumorref,rnanoralt,rnanorref \n",
    "def snvindel(vtype,snvindel,readcount):\n",
    "        chrom,pos,ref,alt = snvindel\n",
    "        chrom = chrom[3:] if chrom[:3].lower() == 'chr' else chrom\n",
    "        chrom = corectchr.CORECTCHR(chrom)\n",
    "        JS = PARSEREADCOUNT(vtype,readcount)\n",
    "        ID = '\\t'.join([chrom,pos,ref,alt])\n",
    "        return ID,JS\n",
    "\n",
    "def PARSEREADCOUNT(vartype,rc):\n",
    "     k2v = {'wgstumoralt':'tumor_DNA_WGS_alt','wgstumorref':'tumor_DNA_WGS_ref','wgsnoralt':'germline_DNA_WGS_alt','wgsnorref':'germline_DNA_WGS_ref',\n",
    "               'cgitumoralt':'tumor_DNA_CGI_alt','cgitumorref':'tumor_DNA_CGI_ref','cginoralt':'germline_DNA_CGI_alt','cginorref':'germline_DNA_CGI_ref',\n",
    "               'westumoralt':'tumor_DNA_WES_alt','westumorref':'tumor_DNA_WES_ref','wesnoralt':'germline_DNA_WES_alt','wesnorref':'germline_DNA_WES_ref',\n",
    "               'cctumoralt':'tumor_DNA_CC_alt','cctumorref':'tumor_DNA_CC_ref','ccnoralt':'germline_DNA_CC_alt','ccnorref':'germline_DNA_CC_ref',\n",
    "               'rnatumoralt':'tumor_RNA_alt','rnatumorref':'tumor_RNA_ref','rnanoralt':'germline_RNA_alt','rnanorref':'germline_RNA_ref',}\n",
    "    k = [[['wgstumoralt','wgstumorref'],['wgsnoralt','wgsnorref']],[['cgitumoralt','cgitumorref'],['cginoralt','cginorref']],[['westumoralt','westumorref'],['wesnoralt','wesnorref']],\n",
    "                [['cctumoralt','cctumorref'],['ccnoralt','ccnorref']],[['rnatumoralt','rnatumorref'],['rnanoralt','rnanorref']]]\n",
    "    if vartype:\n",
    "        JSINFO = {'vorigin':vartype}\n",
    "    else:\n",
    "        JSINFO = {}\n",
    "    for t,g in k:\n",
    "        tval = GETREADCOUNT(t,rc)\n",
    "        gval = GETREADCOUNT(g,rc)\n",
    "        if tval:\n",
    "            for i in [0,1]:\n",
    "                JSINFO[k2v[t[i]]] = tval[i]\n",
    "            if gval:\n",
    "                for i in [0,1]:\n",
    "                    JSINFO[k2v[g[i]]] = gval[i]\n",
    "    if 'tumor_DNA_WGS_alt' in JSINFO:\n",
    "        JSINFO['dna_assay'] = 'wgs'\n",
    "    elif 'tumor_DNA_CGI_alt' in JSINFO:\n",
    "        JSINFO['dna_assay'] = 'cgi'\n",
    "    elif 'tumor_DNA_WES_alt' in JSINFO:\n",
    "        JSINFO['dna_assay'] = 'wes'\n",
    "    return JSINFO\n",
    "    \n",
    "#used in PARSEREADCOUNT\n",
    "def GETREADCOUNT(k,rc):\n",
    "        rtv = False\n",
    "        k1,k2 = k\n",
    "        if k1 in rc and k2 in rc and str(rc[k1]) and str(rc[k2]):\n",
    "                k1val = int(rc[k1])\n",
    "                k2val = int(rc[k2])\n",
    "                if k1val != 0 or k2val != 0:\n",
    "                        rtv = [k1val,k2val]\n",
    "        return rtv\n",
    "def CORECTCHR(c):\n",
    "        CHRD = {'23':'X','24':'Y','MT':'M','chr23':'chrX','chr24':'chrY','chrMT':'chrM'}\n",
    "        if c in CHRD:\n",
    "                return CHRD[c]\n",
    "        else:\n",
    "                return c\n",
    "\n",
    "            \n",
    "#convert snvindel data-store file to vcf file\n",
    "#input: snvindel data-store file\n",
    "#       vcf header file\n",
    "#output vcf file\n",
    "def DATASTORE2VCF(dsfile,headerfile,outputvcf):\n",
    "    out = open(outputvcf,'w')\n",
    "    headerfh = open(headerfile)\n",
    "    for i in headerfh:\n",
    "        out.write(i.strip()+'\\n')\n",
    "    headerfh.close()\n",
    "    SAMPLES = set()\n",
    "    VARSamVal = {}\n",
    "    fh = open(dsfile)\n",
    "    for line in fh:\n",
    "        line = line.replace('\\n','')\n",
    "        lineL = line.split('\\t')\n",
    "        JS = json.loads(lineL[4])\n",
    "        ID = '\\t'.join(lineL[0:4])\n",
    "        FormatSamVal,rtSamples = PARSEJS(JS)\n",
    "        VARSamVal[ID] = FormatSamVal\n",
    "        SAMPLES.update(rtSamples)\n",
    "    fh.close()\n",
    "    SAMPLES = list(SAMPLES)\n",
    "    out.write('\\t'.join(['#CHROM','POS','ID','REF','ALT','QUAL','FILTER','INFO','FORMAT']+SAMPLES)+'\\n')\n",
    "    for id in VARSamVal:\n",
    "        if len(VARSamVal[id]) < 3:\n",
    "            print(id,VARSamVal[id])\n",
    "            continue\n",
    "        outformat = VARSamVal[id][0]\n",
    "        outsams = VARSamVal[id][1]\n",
    "        outvals = VARSamVal[id][2]\n",
    "        chron,pos,REF,ALT = id.split('\\t')\n",
    "        formatLength = outformat.split(':')\n",
    "        outValList = [':'.join(['.']*len(formatLength))] * len(SAMPLES)\n",
    "        for x,s in enumerate(outsams):\n",
    "            IDX = SAMPLES.index(s)\n",
    "            outValList[IDX] = outvals[x]\n",
    "        outlist = [chron,pos,'.',REF,ALT,'.','.','.',outformat] + outValList\n",
    "        out.write('\\t'.join(outlist)+'\\n')\n",
    "    out.close()\n",
    "        \n",
    "def PARSEJS(samvaljs):\n",
    "        SamVal = []\n",
    "        rtSamples = GETSAMPLE(samvaljs.keys()) #function GETSAMPLE\n",
    "        PARSEJS_FORMAT_List = SETFORMAT(samvaljs)\n",
    "        PARSEJS_FORMAT = ':'.join(PARSEJS_FORMAT_List)\n",
    "        SamVal.append(PARSEJS_FORMAT)\n",
    "        for s in samvaljs:\n",
    "                samvallist = []\n",
    "                for attrkey in PARSEJS_FORMAT_List:\n",
    "                        if 'tumor' in attrkey or 'germline' in attrkey:\n",
    "                                if attrkey+'_ref' in samvaljs[s] and attrkey+'_alt' in samvaljs[s]:\n",
    "                                        samvallist.append(str(samvaljs[s][attrkey+'_ref'])+','+str(samvaljs[s][attrkey+'_alt']))\n",
    "                                elif attrkey+'_ref' in samvaljs[s] or attrkey+'_alt' in samvaljs[s]:\n",
    "                                        print('only have reads count for ref or alt: ',file=sys.stderr)\n",
    "                                else:\n",
    "                                        samvallist.append('.')\n",
    "                        else:\n",
    "                                if attrkey in samvaljs[s]:\n",
    "                                        samvallist.append(samvaljs[s][attrkey])\n",
    "                                else:\n",
    "                                        samvallist.append('.')\n",
    "                if len(SamVal) == 1:\n",
    "                        SamVal.append([s])\n",
    "                        SamVal.append([':'.join(samvallist)])\n",
    "                elif len(SamVal) > 1:\n",
    "                        SamVal[1].append(s)\n",
    "                        SamVal[2].append(':'.join(samvallist))\n",
    "                else:\n",
    "                        print('no format generated for:',file=sys.stderr)\n",
    "        return SamVal,rtSamples\n",
    "def GETSAMPLE(sams):\n",
    "    RTSAM = set()\n",
    "    for s in sams:\n",
    "        RTSAM.add(s)\n",
    "    return RTSAM\n",
    "\n",
    "#get final format for vcf file \n",
    "def SETFORMAT(fjs):\n",
    "        setformat_format = ['tumor_DNA_WGS',\\\n",
    "                        'germline_DNA_WGS',\\\n",
    "                        'tumor_DNA_CGI',\\\n",
    "                        'germline_DNA_CGI',\\\n",
    "                        'tumor_DNA_WES',\\\n",
    "                        'germline_DNA_WES',\\\n",
    "                        'tumor_DNA',\\\n",
    "                        'germline_DNA',\\\n",
    "                        'tumor_DNA_CC',\\\n",
    "                        'germline_DNA_CC',\\\n",
    "                        'tumor_RNA',\\\n",
    "                        'dna_assay',\\\n",
    "                        'pantargetsignature',\\\n",
    "                        'tcgaskcmsignature',\\\n",
    "                        'project',\\\n",
    "                        'vorigin',\\\n",
    "                        'pmid']\n",
    "        allkey = set()\n",
    "        for sam in fjs.keys():\n",
    "                for k in fjs[sam]:\n",
    "                        if 'tumor' in k or 'germline' in k:\n",
    "                                testk = k[:-4]\n",
    "                        else:\n",
    "                                testk = k\n",
    "                        allkey.add(testk)\n",
    "        format_list = []\n",
    "        for fk in setformat_format:\n",
    "                if fk in allkey:\n",
    "                        format_list.append(fk)\n",
    "        return format_list\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile VCFheader\n",
    "##fileformat=VCFv4.2\n",
    "##FILTER=<ID=PASS,Description=\"All filters passed\">\n",
    "##FORMAT=<ID=tumor_DNA_WGS,Number=R,Type=Integer,Description=\"Allelic depths for the ref and alt alleles in the order listed, tumor WGS\">\n",
    "##FORMAT=<ID=germline_DNA_WGS,Number=R,Type=Integer,Description=\"Allelic depths for the ref and alt alleles in the order listed, germline WGS\">\n",
    "##FORMAT=<ID=tumor_DNA_WES,Number=R,Type=Integer,Description=\"Allelic depths for the ref and alt alleles in the order listed, tumor WES\">\n",
    "##FORMAT=<ID=germline_DNA_WES,Number=R,Type=Integer,Description=\"Allelic depths for the ref and alt alleles in the order listed, germline WES\">\n",
    "##FORMAT=<ID=dna_assay,Number=1,Type=String,Description=\"Source of the variant generated from, can be cgi,wgs,wes\">\n",
    "##contig=<ID=1,length=248956422>\n",
    "##contig=<ID=2,length=242193529>\n",
    "##contig=<ID=3,length=198295559>\n",
    "##contig=<ID=4,length=190214555>\n",
    "##contig=<ID=5,length=181538259>\n",
    "##contig=<ID=6,length=170805979>\n",
    "##contig=<ID=7,length=159345973>\n",
    "##contig=<ID=8,length=145138636>\n",
    "##contig=<ID=9,length=138394717>\n",
    "##contig=<ID=10,length=133797422>\n",
    "##contig=<ID=11,length=135086622>\n",
    "##contig=<ID=12,length=133275309>\n",
    "##contig=<ID=13,length=114364328>\n",
    "##contig=<ID=14,length=107043718>\n",
    "##contig=<ID=15,length=101991189>\n",
    "##contig=<ID=16,length=90338345>\n",
    "##contig=<ID=17,length=83257441>\n",
    "##contig=<ID=18,length=80373285>\n",
    "##contig=<ID=19,length=58617616>\n",
    "##contig=<ID=20,length=64444167>\n",
    "##contig=<ID=21,length=46709983>\n",
    "##contig=<ID=22,length=50818468>\n",
    "##contig=<ID=X,length=156040895>\n",
    "##contig=<ID=Y,length=57227415>\n",
    "##contig=<ID=M,length=16569>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate vcf file\n",
    "import snvindel\n",
    "\n",
    "#generate data store file\n",
    "optattr = ['dna_assay']\n",
    "infile = 'panallsnvindel'\n",
    "outfile = 'panall.hg38.datastore'\n",
    "snvindel.GENSNVINDEL(infile,outfile,optattr=optattr)\n",
    "\n",
    "#generate vcf file\n",
    "vcfinput = 'panall.hg38.datastore'\n",
    "vcfheader = 'VCFheader'\n",
    "vcfoutfile = 'panall.hg38.vcf'\n",
    "snvindel.DATASTORE2VCF(vcfinput,vcfheader,vcfoutfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 pan-ALL sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions to generate svfusion file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile svfusion.py \n",
    "\n",
    "#!/usr/bin/python3\n",
    "\n",
    "import sys,os\n",
    "import json\n",
    "from decimal import Decimal\n",
    "    \n",
    "#infile: input file \n",
    "#outfile: output file\n",
    "#assay: data type. could be fusion, cnv, loh and sv\n",
    "#optattr: attributes which is optional. keys can be anything including 'vorigin', 'dna_assay' and 'pmid'\n",
    "#return all samples in input file \n",
    "def GENVARFH(infile,outfile,assay,optattr={}):\n",
    "        fh = open(infile)\n",
    "        out = open(outfile,'w')\n",
    "        HEAD = fh.readline().strip().split('\\t')\n",
    "        samidx = HEAD.index('sample_name')\n",
    "        sample = set()\n",
    "        if optattr:\n",
    "                optkey = list(optattr.keys())\n",
    "                HEAD.extend(optkey)\n",
    "                optval = [optattr[x] for x in optkey]\n",
    "        else:\n",
    "                optkey = []\n",
    "        for line in fh:\n",
    "                L = line.replace('\\n','').split('\\t')\n",
    "                sample.add(L[samidx])\n",
    "                if optkey:\n",
    "                        L.extend(optval)\n",
    "                RT = SVFUSION(assay,HEAD,optkey,L)\n",
    "                out.write(RT)\n",
    "        out.close()\n",
    "        fh.close()\n",
    "        return sample\n",
    "\n",
    "#vtype: 'sv' or 'fusion'\n",
    "#vhead svhead = ['sample_name', 'gene_a', 'chr_a', 'position_a', 'strand_a', 'gene_b', 'chr_b', 'position_b','strand_b','vorigin','dna_assay','manual_review']\n",
    "#voptatrr svoptatrr = ['vorigin','dna_assay','manual_review']\n",
    "#valuelist value should correspond to vhead\n",
    "def SVFUSION(vtype,vhead,voptatrr,valuelist):\n",
    "        if vtype == 'sv':\n",
    "                n = 5\n",
    "        elif vtype == 'fusion':\n",
    "                n = 2\n",
    "        return PARSEFUSV(valuelist,vhead,voptatrr,n)\n",
    "\n",
    "################\n",
    "#SV & Fusion\n",
    "def PARSEFUSV(L,headL,optattr,dt):\n",
    "        ca = L[headL.index('chr_a')]\n",
    "        ca = 'chr'+ca[3:] if ca[0:3].lower() == 'chr' else 'chr'+ca\n",
    "        cb = L[headL.index('chr_b')]\n",
    "        cb = 'chr'+cb[3:] if cb[0:3].lower() == 'chr' else 'chr'+cb\n",
    "        psa = L[headL.index('position_a')]\n",
    "        psa = POSMIN1(psa)\n",
    "        psb = L[headL.index('position_b')]\n",
    "        psb = POSMIN1(psb)\n",
    "        stda = L[headL.index('strand_a')]\n",
    "        stdb = L[headL.index('strand_b')]\n",
    "        if 'gene_a' in headL:\n",
    "                ga = L[headL.index('gene_a')].strip()\n",
    "                ga = CHANGENENAME(ga)\n",
    "        else:\n",
    "                ga = False\n",
    "        if 'gene_b' in headL:\n",
    "                gb = L[headL.index('gene_b')].strip()\n",
    "                gb = CHANGENENAME(gb)\n",
    "        else:\n",
    "                gb = False\n",
    "        sam = L[headL.index('sample_name')]\n",
    "        JSA = {'dt':dt,'strandA':stda,'strandB':stdb,'sample':sam}\n",
    "        if 'svtype' in headL:\n",
    "                svtype = L[headL.index('svtype')]\n",
    "                if svtype:\n",
    "                        JSA['svtype'] = svtype\n",
    "        readList = ['clipreadA','clipreadB','totalreadA','totalreadB']\n",
    "        for readk in readList:\n",
    "                if readk in headL:\n",
    "                        readv = L[headL.index(readk)]\n",
    "                        if readv and readv.isdigit():\n",
    "                                readv = int(readv)\n",
    "                                if readv == 0:\n",
    "                                        continue\n",
    "                                JSA[readk] = readv\n",
    "        if ga:\n",
    "                JSA['geneA'] = ga\n",
    "        if gb:\n",
    "                JSA['geneB'] = gb\n",
    "        mattr = PARSEMATTR(L,headL,optattr)\n",
    "        if mattr:\n",
    "                JSA['mattr'] = mattr\n",
    "        JSB = JSA.copy()\n",
    "        JSA['chrB'] = cb\n",
    "        JSA['posB'] = int(psb)\n",
    "        JSB['chrA'] = ca\n",
    "        JSB['posA'] = int(psa)\n",
    "        return '\\t'.join([ca,psa,psa,json.dumps(JSA,sort_keys=True)])+'\\n'+'\\t'.join([cb,psb,psb,json.dumps(JSB,sort_keys=True)])+'\\n'\n",
    "\n",
    "def POSMIN1(p):\n",
    "        return str(int(Decimal(p))-1)\n",
    "\n",
    "def CHANGENENAME(g):\n",
    "        if g == 'NA' or ',' in g:\n",
    "                return False\n",
    "        else:\n",
    "                return g\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'liftover'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mliftover\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_lifter\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#hg38 coordinate convertion\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mCOVHG38\u001b[39m(orgchr,liftoverout):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'liftover'"
     ]
    }
   ],
   "source": [
    "#generate mds sv file\n",
    "#input is sv table from PAN-ALL paper supplimentary table. file name: \"sv\"\n",
    "#require the python package called liftover\n",
    "\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "from liftover import get_lifter\n",
    "import svfusion\n",
    "\n",
    "#hg38 coordinate convertion\n",
    "def COVHG38(orgchr,liftoverout):\n",
    "    pos = ''\n",
    "    for e in liftoverout:\n",
    "        hg38chr,hg38pos,hg38std = e\n",
    "        hg38chr = hg38chr[3:] if hg38chr[:3].lower() == 'chr' else hg38chr\n",
    "        if hg38chr == orgchr:\n",
    "            pos = str(hg38pos)\n",
    "    return pos\n",
    "\n",
    "#liftover\n",
    "converter = get_lifter('hg19','hg38')\n",
    "\n",
    "fh = open('sv')\n",
    "out = open('panallsv','w')\n",
    "out.write('\\t'.join(['chr_a','chr_b','position_a','position_b','strand_a','strand_b','gene_a','gene_b','sample_name','svtype'])+'\\n')\n",
    "\n",
    "for line in fh:\n",
    "    l = line.strip().split('\\t')\n",
    "    OUTL = []\n",
    "    sample = l[1]\n",
    "    chroma = l[2]\n",
    "    chroma = chroma if chroma[:3].lower() == 'chr' else 'chr'+chroma\n",
    "    chromb = l[5]\n",
    "    chromb = chromb if chromb[:3].lower() == 'chr' else 'chr'+chromb\n",
    "    posa = l[3]\n",
    "    stda = l[4]\n",
    "    posb = l[6]\n",
    "    stdb = l[7]\n",
    "    svt = l[8]\n",
    "    hg38Cora = converter[chroma][int(posa)]\n",
    "    posa = COVHG38(chroma,hg38Cora)\n",
    "    if not posa:\n",
    "        continue\n",
    "    hg38Corb = converter[chromb][int(posb)]\n",
    "    posb = COVHG38(chromb,hg38Corb)\n",
    "    if not posb:\n",
    "        continue\n",
    "    if l[13]:\n",
    "        if ',' in l[13]:\n",
    "            ga = l[13].strip().split(',')[0]\n",
    "        else:\n",
    "            ga = l[13]\n",
    "    else:\n",
    "        ga = ''\n",
    "    if l[14]:\n",
    "        if ',' in l[14]:\n",
    "            gb = l[14].strip().split(',')[0]\n",
    "        else:\n",
    "            gb = l[14]\n",
    "    else:\n",
    "        gb = ''\n",
    "    OUTL = [chroma,chromb,posa,posb,stda,stdb,ga,gb,sample,svt]\n",
    "    out.write('\\t'.join(OUTL)+'\\n')\n",
    "out.close()\n",
    "fh.close()\n",
    "\n",
    "#gernate mds sv file\n",
    "svfusion('panallsv','panall.hg38.sv','sv')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 pan-ALL fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pan-ALL fusion\n",
    "#coordinate can not be found from pan-ALL paper supplementary table\n",
    "#fusion data was extracted from pediatric data plus some data from kohei.\n",
    "#current fusion data only avilable for some of pan-ALL samples not all\n",
    "#fusion file 'panall.hg38.fusion'\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
