{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00eb531f",
   "metadata": {},
   "source": [
    "#  <center>LD computing</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe46b02",
   "metadata": {},
   "source": [
    "This page documents the LD computing. <br>The input files: <br>&nbsp;&nbsp;&nbsp;&nbsp;1. vcf file with INFO and GT fields (multiallelic variant is not allowed) <br>&nbsp;&nbsp;&nbsp;&nbsp;2. sample list with integer ID for (CEU and YRI)</font><p>Computing steps: <br> &nbsp;&nbsp;&nbsp;&nbsp;1. Extract vcf file containing only good variants and samples in sample list file  <br> &nbsp;&nbsp;&nbsp;&nbsp;2. Set id field in vcf file as 'CHROM.POS.REF.ALT' <br> &nbsp;&nbsp;&nbsp;&nbsp;3. Generate Plink format files <br> &nbsp;&nbsp;&nbsp;&nbsp;4. LD computing <br> &nbsp;&nbsp;&nbsp;&nbsp;5. generate ld bed file <br>&nbsp;&nbsp;&nbsp;&nbsp; 6. sort and index LD bed file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b506f7",
   "metadata": {},
   "source": [
    "## working directory and required file setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b70e6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Done\n",
      "PLINK v1.90b3w 64-bit (3 Sep 2015)         https://www.cog-genomics.org/plink2\n",
      "(C) 2005-2015 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "\n",
      "  plink [input flag(s)...] {command flag(s)...} {other flag(s)...}\n",
      "  plink --help {flag name(s)...}\n",
      "\n",
      "Commands include --make-bed, --recode, --flip-scan, --merge-list,\n",
      "--write-snplist, --list-duplicate-vars, --freqx, --missing, --test-mishap,\n",
      "--hardy, --mendel, --ibc, --impute-sex, --indep-pairphase, --r2, --show-tags,\n",
      "--blocks, --distance, --genome, --homozyg, --make-rel, --make-grm-gz,\n",
      "--rel-cutoff, --cluster, --pca, --neighbour, --ibs-test, --regress-distance,\n",
      "--model, --bd, --gxe, --logistic, --dosage, --lasso, --test-missing,\n",
      "--make-perm-pheno, --tdt, --qfam, --annotate, --clump, --gene-report,\n",
      "--meta-analysis, --epistasis, --fast-epistasis, and --score.\n",
      "\n",
      "'plink --help | more' describes all functions (warning: long).\n"
     ]
    }
   ],
   "source": [
    "import subprocess as sp\n",
    "\n",
    "#working direcotry\n",
    "workingDir = '/research/rgs01/resgen/legacy/gb_customTracks/tp/jwang/TASK/survivorship/PLINK/LD2'\n",
    "\n",
    "#vcf file directory\n",
    "vcffileDir = '/research/rgs01/resgen/legacy/gb_customTracks/tp/jwang/TASK/survivorship/bcf/SNV/matrix2VCF'\n",
    "CHR = ['chr'+str(x+1) for x in range(22)]\n",
    "vcffiles = {x:os.path.join(vcffileDir,x+'.vcf.gz') for x in CHR}\n",
    "\n",
    "#sample list (integer ID)\n",
    "#European sample ID\n",
    "CEUID = '/research/rgs01/resgen/legacy/gb_customTracks/tp/jwang/TASK/survivorship/PLINK/LD2/CEUID'\n",
    "YRIID = '/research/rgs01/resgen/legacy/gb_customTracks/tp/jwang/TASK/survivorship/PLINK/LD2/YRIID'\n",
    "print('Setup Done')\n",
    "\n",
    "#check if plink is in $PATH\n",
    "ckrt = sp.run('plink',shell=True,stderr=sp.PIPE).stderr.decode('utf-8')\n",
    "if 'command not found' in ckrt:\n",
    "    print('Please load plink before you start jupyter notebook: <module load plink/1.90b>')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44e45e7",
   "metadata": {},
   "source": [
    "## 1. Extract vcf file containing only good variants and samples in sample list file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "120b5e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job <173912477> is submitted to queue <standard>.\n",
      "extracting good variants from chr21\n",
      "Job <173912478> is submitted to queue <standard>.\n",
      "extracting good variants from chr22\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "popsSample = {'ceu':CEUID,'yri':YRIID}\n",
    "extVarFiles = []\n",
    "for c in CHR:\n",
    "    for p in popsSample:\n",
    "        pDir = os.path.join(workingDir,p)\n",
    "        if not os.path.isdir(pDir):\n",
    "            os.system('mkdir -p ' + pDir)\n",
    "        varFile = os.path.join(pDir,c+'.'+p+'.vcf.gz')\n",
    "        extVarFiles.append(varFile)\n",
    "        extCommand = 'bsub -q standard -R \"rusage[mem=2000]\"'\n",
    "        extCommand += ' -oo ' + varFile + '.ext.log'\n",
    "        extCommand += ' -eo ' + varFile + '.ext.elog'\n",
    "        extCommand += ' bcftools view -S ' + popsSample[p]\n",
    "        extCommand += ' -i ' + \"\"\"QC='\"Good\"' -O z\"\"\"\n",
    "        extCommand += ' -o ' + varFile\n",
    "        extCommand += ' ' + vcffiles[c]\n",
    "        os.system(extCommand)\n",
    "    print('extracting good variants from ' + c)\n",
    "#extracted variant file\n",
    "with open('var.ext','w') as output:\n",
    "    json.dump(extVarFiles,output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bf61d1",
   "metadata": {},
   "source": [
    "## 2. Set id field in vcf file as 'CHROM.POS.REF.ALT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d04400e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job <173916384> is submitted to queue <standard>.\n",
      "Job <173916385> is submitted to queue <standard>.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "with open('var.ext') as input:\n",
    "    extVarFiles = json.load(input)\n",
    "#check if vcf file containing only good variants and samples in sample list file available\n",
    "for vf in extVarFiles:\n",
    "    if not os.path.isfile(vf):\n",
    "        print('vcf extracting above was not successful!')\n",
    "        print('Please re-run')\n",
    "\n",
    "#Set id field in vcf file as 'CHROM.POS.REF.ALT'\n",
    "for vf in extVarFiles:\n",
    "    idchgCommand = 'bsub -q standard -R \"rusage[mem=2000]\"'\n",
    "    idchgCommand += ' -oo ' + vf + '.idchg.log'\n",
    "    idchgCommand += ' -eo ' + vf + '.idchg.elog'\n",
    "    idchgCommand += \" bcftools annotate --set-id +\\'%CHROM\\.%POS\\.%REF\\.%ALT\\' \"+vf\n",
    "    idchgCommand += ' -O z -o ' + vf + '.idchg.gz'\n",
    "    os.system(idchgCommand)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f3bf26",
   "metadata": {},
   "source": [
    "## 3. Generate Plink format files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e88bc257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job <173916934> is submitted to queue <standard>.\n",
      "Job <173916935> is submitted to queue <standard>.\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import json\n",
    "import subprocess as sp\n",
    "\n",
    "with open('var.ext') as input:\n",
    "    extVarFiles = json.load(input)\n",
    "\n",
    "\n",
    "#check if id field is replaced\n",
    "for vf in extVarFiles:\n",
    "    ckrt = sp.run('bcftools query -f \"[%ID\\n]\" '+vf+ '.idchg.gz'+'|head -n 1',shell=True,stdout=sp.PIPE).stdout.decode('utf-8').strip()\n",
    "    if ckrt == '.':\n",
    "        print('ID replacement above was not successful!')\n",
    "        print('please re-run')\n",
    "        sys.exit(1)\n",
    "\n",
    "#Generate Plink format files\n",
    "for vf in extVarFiles:\n",
    "    os.system('mv '+vf+ '.idchg.gz '+vf)\n",
    "    vfDir,vfFile = os.path.split(vf)\n",
    "    chrom = vfFile.split('.')[0]\n",
    "    pfileCommand = 'bsub -q standard -R \"rusage[mem=2000]\"'\n",
    "    pfileCommand += ' -oo ' + vf + '.pfile.log'\n",
    "    pfileCommand += ' -eo ' + vf + '.pfile.elog'\n",
    "    pfileCommand += ' plink --vcf ' + vf + ' --maf 0.05 --make-bed --out ' + os.path.join(vfDir,chrom)\n",
    "    os.system(pfileCommand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377eae7c",
   "metadata": {},
   "source": [
    "## 4. LD computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ce4a1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job <173917334> is submitted to queue <standard>.\n",
      "Job <173917336> is submitted to queue <standard>.\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import json\n",
    "\n",
    "with open('var.ext') as input:\n",
    "    extVarFiles = json.load(input)\n",
    "\n",
    "#check if plink files generated\n",
    "for vf in extVarFiles:\n",
    "    vfDir,vfFile = os.path.split(vf)\n",
    "    chrom = vfFile.split('.')[0]\n",
    "    if not os.path.isfile(os.path.join(vfDir,chrom+'.fam')):\n",
    "        print('plink files was not generated.')\n",
    "        print('please re-run the step above')\n",
    "        sys.exit(1)\n",
    "#LD computing\n",
    "for vf in extVarFiles:\n",
    "    vfDir,vfFile = os.path.split(vf)\n",
    "    chrom = vfFile.split('.')[0]\n",
    "    ldCommand = 'bsub -q standard -R \"rusage[mem=30000]\"'\n",
    "    ldCommand += ' -oo ' + vf + '.ld.log'\n",
    "    ldCommand += ' -eo ' + vf + '.ld.elog'\n",
    "    ldCommand += ' plink --bfile ' + os.path.join(vfDir,chrom)\n",
    "    ldCommand += ' --r2 --ld-window-kb 200 --ld-window 99999 --ld-window-r2 0.1'\n",
    "    ldCommand += ' --out ' + os.path.join(os.path.join(vfDir,chrom))\n",
    "    os.system(ldCommand)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eb57cf",
   "metadata": {},
   "source": [
    "## 5. generate ld bed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a40a093c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job <173917988> is submitted to queue <standard>.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.isfile('genLdBed.py'):\n",
    "    print('Please run scripts used for LD computing below')\n",
    "\n",
    "for p in popsSample:\n",
    "    pDir = os.path.join(workingDir,p)\n",
    "    ldbedCommand = 'bsub -q standard -R \"rusage[mem=30000]\"'\n",
    "    ldbedCommand += ' -oo ' + pDir + '/'+p+'.ldbed.log'\n",
    "    ldbedCommand += ' -eo ' + pDir + '/'+p+'.ldbed.elog'\n",
    "    ldbedCommand += ' python3 genLdBed.py '+pDir+' '+p\n",
    "    os.system(ldbedCommand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e312663c",
   "metadata": {},
   "source": [
    "## 6. sort and index LD bed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba7d1bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job <173920050> is submitted to queue <standard>.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.isfile('sortbed.sh'):\n",
    "    print('Please run scripts used for LD computing below')\n",
    "\n",
    "for p in popsSample:\n",
    "    ldbedFile = os.path.join(*[workingDir,p,p.upper()])\n",
    "    sortindexCommand = 'bsub -q standard -R \"rusage[mem=30000]\"'\n",
    "    sortindexCommand += ' -oo ' + pDir + '/'+p+'.sortindexldbed.log'\n",
    "    sortindexCommand += ' -eo ' + pDir + '/'+p+'.sortindexldbed.elog'\n",
    "    sortindexCommand += ' sh sortbed.sh ' + ldbedFile\n",
    "    os.system(sortindexCommand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9b1bdc",
   "metadata": {},
   "source": [
    "## Scripts used for LD computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f743793a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting genLdBed.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile genLdBed.py\n",
    "\n",
    "#!/usr/bin/python3\n",
    "\n",
    "\"\"\"\n",
    "Generate sorted and indexed ld file \n",
    "\tinput: direcotry where ld files for each chromosome generated from plink were located\n",
    "\toutput: A single ld bed file\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "ldDir = sys.argv[1]\n",
    "pop = sys.argv[2]\n",
    "CHR = ['chr'+str(x+1) for x in range(22)]\n",
    "out = open(os.path.join(ldDir,pop.upper()),'w')\n",
    "\n",
    "\n",
    "for c in CHR:\n",
    "    ldfile = os.path.join(ldDir,c+'.ld')\n",
    "    if not os.path.isfile(ldfile):\n",
    "        print(ldfile + ' does not exist!')\n",
    "        sys.exit(1)\n",
    "    fh = open(ldfile)\n",
    "    fh.readline()\n",
    "    for line in fh:\n",
    "        l = re.split('\\s+',line.strip())\n",
    "        chrom = 'chr'+l[0]\n",
    "        p1 = str(int(l[1])-1)\n",
    "        p2 = str(int(l[4])-1)\n",
    "        out.write('\\t'.join([chrom,l[1],l[4],l[2][-3:],l[5][-3:],l[-1]])+'\\n')\n",
    "    fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df063500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sortbed.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile sortbed.sh\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "file=$1\n",
    "\n",
    "\n",
    "sort -k1,1 -k2,2n $file >${file}.sort\n",
    "mv ${file}.sort $file\n",
    "bgzip $file\n",
    "tabix -p bed ${file}.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8f2c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
