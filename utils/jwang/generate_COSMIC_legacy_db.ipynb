{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Generate COSMIC legacy db</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">This page documents the download, cleanup, annotation process and legacy db file generating for COSMIC <p>1. you need to specify the working directory below where SNVindel and fusion data downloaded from <a href=\"https://cancer.sanger.ac.uk/cosmic\">https://cancer.sanger.ac.uk/cosmic</a> can be found. The default working directory will be in the same place as the current note book file.<br>2. you need to specify the cosmic version and genome version. <br>3. follow the wiki page (<a href=\"https://wiki.stjude.org/display/compbio/How+to+clean+and+annotate+the+COSMIC+database\">https://wiki.stjude.org/display/compbio/How+to+clean+and+annotate+the+COSMIC+database</a>) to clean and annotate the COSMIC database<br><font color = red>4. it is supposed to run on hpc <br>5. run each of the cell that starts with %%writefile first <br>6. Session setup. run the following commands before you start your jupyter notebook:<br>&nbsp;&nbsp;&nbsp;&nbsp;setcbenv prod<br>&nbsp;&nbsp;&nbsp;&nbsp;cbload clinical-classifier<br>&nbsp;&nbsp;&nbsp;&nbsp;cbload snv-annovar<br>&nbsp;&nbsp;&nbsp;&nbsp;cbload snv-vep<br>&nbsp;&nbsp;&nbsp;&nbsp;cbload util-scripts<br>&nbsp;&nbsp;&nbsp;&nbsp;module load vcftools<br>&nbsp;&nbsp;&nbsp;&nbsp;module load htslib/1.15.1<br>&nbsp;&nbsp;&nbsp;&nbsp;module load vep/v100<font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <font color = blue>&nbsp;&nbsp;&nbsp;&nbsp;Session Setup<br></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session setup successfully!\n"
     ]
    }
   ],
   "source": [
    "#check the Session setup\n",
    "import subprocess as sp\n",
    "ckrt = sp.run('vcf2tab.pl',shell=True,stderr=sp.PIPE).stderr.decode('utf-8')\n",
    "if 'command not found' in ckrt:\n",
    "    print('Please finish the session setup steps as shown in RED above in the instruction')\n",
    "    sessionSetup = False\n",
    "else:\n",
    "    sessionSetup = True\n",
    "    print('Session setup successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. <font color = blue>&nbsp;&nbsp;&nbsp;&nbsp;Specify the working directory<br>&nbsp;&nbsp;&nbsp;&nbsp;Specify genome version</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working directory: ./\n",
      "genome version: hg19\n"
     ]
    }
   ],
   "source": [
    "#specify the working directory\n",
    "working_dir = './' \n",
    "os.chdir(working_dir)\n",
    "print('working directory: '+working_dir)\n",
    "\n",
    "#genome version\n",
    "genome_v = 'hg19'#speicify the genome version ( hg19 or hg38 )\n",
    "genome_version_name = {'hg38':'GRCh38','hg19':'GRCh37'}\n",
    "print('genome version: '+genome_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. <font color = blue>&nbsp;&nbsp;&nbsp;&nbsp;Check the downloaded files<br></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files have been downloaded. Please move forward to the next step!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "if not sessionSetup:\n",
    "    print('Please finish the session setup steps as shown in RED above in the instruction')\n",
    "    sys.exit(1)\n",
    "\n",
    "#check if the required files are available\n",
    "cosmicFiles = [x+'_'+genome_version_name[genome_v]+'.tsv.gz' \n",
    "               for x in ['CosmicCodingMuts','CosmicFusionExport','CosmicMutantExport']]\n",
    "for f in cosmicFiles:\n",
    "    if not os.path.isfile(f):\n",
    "        print('Error:')\n",
    "        print('\\tPlease download the file from https://cancer.sanger.ac.uk/cosmic')\n",
    "        sys.exit(1)\n",
    "print('All files have been downloaded. Please move forward to the next step!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. <font color=blue>&nbsp;&nbsp;&nbsp;&nbsp;VCF allele extraction</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job <171020600> is submitted to queue <standard>.\n"
     ]
    }
   ],
   "source": [
    "#VCF allele extraction\n",
    "\n",
    "if not sessionSetup:\n",
    "    print('Please finish the session setup steps as shown in RED above in the instruction')\n",
    "    sys.exit(1)\n",
    "    \n",
    "import os\n",
    "if genome_v == 'hg38':\n",
    "    os.system('bsub <vcf_allele_ext_hg38.sh')\n",
    "elif genome_v == 'hg19':\n",
    "    os.system('bsub <vcf_allele_ext_hg19.sh')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. <font color=blue>&nbsp;&nbsp;&nbsp;&nbsp;genomic allele annotation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job <171022769> is submitted to queue <standard>.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#genomic allele annotation\n",
    "import os,sys\n",
    "\n",
    "if not sessionSetup:\n",
    "    print('Please finish the session setup steps as shown in RED above in the instruction')\n",
    "    sys.exit(1)\n",
    "\n",
    "cooked_tab_file = 'CosmicCodingMuts_'+genome_version_name[genome_v]+'.tsv.gz.cooked.tab'\n",
    "if not os.path.isfile(cooked_tab_file):\n",
    "    print('VCF allele extraction is not done yet! Please wait for the last step to be finished!')\n",
    "    sys.exit(1)\n",
    "os.system('bsub <genoallel_anno_'+genome_v+'.sh')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. <font color=blue>&nbsp;&nbsp;&nbsp;&nbsp;population frequency filtering</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job <171025499> is submitted to queue <standard>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPCF: WARNING! No Memory was requested!\n",
      "      A default memory request of 2.50 GB has been placed for this job\n",
      "      The job will be killed if   2.50 GB of memory is used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#population frequency filtering\n",
    "import os,sys\n",
    "\n",
    "if not sessionSetup:\n",
    "    print('Please finish the session setup steps as shown in RED above in the instruction')\n",
    "    sys.exit(1)\n",
    "\n",
    "genomic_tab_file = 'CosmicMutantExport_'+genome_version_name[genome_v]+'.tsv.gz.genomic.tab'\n",
    "if not os.path.isfile(genomic_tab_file):\n",
    "    print('genomic allele annotation is not done yet! Please wait for the last step to be finished!')\n",
    "    sys.exit(1)\n",
    "os.system('bsub <freqfilter_'+genome_v+'.sh')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. <font color=blue>&nbsp;&nbsp;&nbsp;&nbsp;cleaning</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job <171036674> is submitted to queue <standard>.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning\n",
    "import os,sys\n",
    "\n",
    "if not sessionSetup:\n",
    "    print('Please finish the session setup steps as shown in RED above in the instruction')\n",
    "    sys.exit(1)\n",
    "    \n",
    "exac_filter_file = 'CosmicMutantExport_'+genome_version_name[genome_v]+'.tsv.gz.genomic.tab.exac.tab'\n",
    "if not os.path.isfile(exac_filter_file):\n",
    "    print('genomic allele annotation is not done yet! Please wait for the last step to be finished!')\n",
    "    sys.exit(1)\n",
    "os.system('bsub <cleaning_'+genome_v+'.sh')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. <font color=blue>&nbsp;&nbsp;&nbsp;&nbsp;sorting</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job <171041603> is submitted to queue <standard>.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorting based on genomic position\n",
    "import os,sys\n",
    "\n",
    "if not sessionSetup:\n",
    "    print('Please finish the session setup steps as shown in RED above in the instruction')\n",
    "    sys.exit(1)\n",
    "    \n",
    "cleaned_file = 'CosmicMutantExport_'+genome_version_name[genome_v]+'.tsv.gz.genomic.tab.exac.tab.cleaned.tab'\n",
    "if not os.path.isfile(cleaned_file):\n",
    "    print('genomic allele annotation is not done yet! Please wait for the last step to be finished!')\n",
    "    sys.exit(1)\n",
    "os.system('bsub <sorting_'+genome_v+'.sh')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. <font color=blue>&nbsp;&nbsp;&nbsp;&nbsp;VEP annotation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job <171044928> is submitted to queue <standard>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPCF: WARNING! No Memory was requested!\n",
      "      A default memory request of 2.50 GB has been placed for this job\n",
      "      The job will be killed if   2.50 GB of memory is used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VEP annotation\n",
    "import os,sys\n",
    "\n",
    "if not sessionSetup:\n",
    "    print('Please finish the session setup steps as shown in RED above in the instruction')\n",
    "    sys.exit(1)\n",
    "os.system('bsub <vep_'+genome_v+'.sh')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. <font color=blue>&nbsp;&nbsp;&nbsp;&nbsp;duplicate record removal</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job <171063972> is submitted to queue <standard>.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#duplicate record removal\n",
    "import os,sys\n",
    "\n",
    "if not sessionSetup:\n",
    "    print('Please finish the session setup steps as shown in RED above in the instruction')\n",
    "    sys.exit(1)\n",
    "    \n",
    "hgvs_file = 'CosmicMutantExport_'+genome_version_name[genome_v]+'.tsv.gz.genomic.tab.exac.tab.cleaned.tab.hgvs.tab'\n",
    "if not os.path.isfile(hgvs_file):\n",
    "    print('genomic allele annotation is not done yet! Please wait for the last step to be finished!')\n",
    "    sys.exit(1)\n",
    "    \n",
    "os.system('bsub <duprm_'+genome_v+'.sh')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. <font color=blue>&nbsp;&nbsp;&nbsp;&nbsp;generate snvindel file for db loading</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#generate snvindel file for db loading\n",
    "import os,sys\n",
    "\n",
    "if not sessionSetup:\n",
    "    print('Please finish the session setup steps as shown in RED above in the instruction')\n",
    "    sys.exit(1)\n",
    "    \n",
    "uniq_file = 'CosmicMutantExport_'+genome_version_name[genome_v]+'.tsv.gz.genomic.tab.exac.tab.cleaned.tab.hgvs.tab.unique.tab'\n",
    "if not os.path.isfile(hgvs_file):\n",
    "    print('genomic allele annotation is not done yet! Please wait for the last step to be finished!')\n",
    "    sys.exit(1)\n",
    "snvindelOutputFile = 'cosmic.snvindel.'+genome_v\n",
    "!python3 gencosmicsnvindel.py $uniq_file $snvindelOutputFile\n",
    "print('cosmic.snvindel.'+genome_v+' generated!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. <font color=blue>&nbsp;&nbsp;&nbsp;&nbsp;generate fusion file for db loading</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49957 lines have no fusion name\n",
      "1169 lines with ensemble name cannot be converted to refseq\n",
      "13812 duplicated lines removed\n",
      "7 skipped for lines without breakpoint info\n",
      "5619 skipped for ? in fusion name\n",
      "cosmic.fusion.hg38 generated!\n"
     ]
    }
   ],
   "source": [
    "#generate fusion file for db loading\n",
    "import os,sys\n",
    "\n",
    "if not sessionSetup:\n",
    "    print('Please finish the session setup steps as shown in RED above in the instruction')\n",
    "    sys.exit(1)\n",
    "fusionFile = 'CosmicFusionExport_'+genome_version_name[genome_v]+'.tsv.gz'\n",
    "fusionOutFile = 'cosmic.fusion.'+genome_v\n",
    "!python3 cosmic_fusion.py $fusionFile $genome_v $fusionOutFile\n",
    "print('cosmic.fusion.'+genome_v+' generated!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. <font color=blue>&nbsp;&nbsp;&nbsp;&nbsp;db loading</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosmic.hg38.db generated!\n"
     ]
    }
   ],
   "source": [
    "#db loading\n",
    "import os,sys\n",
    "if not sessionSetup:\n",
    "    print('Please finish the session setup steps as shown in RED above in the instruction')\n",
    "    sys.exit(1)\n",
    "snvindelFile = 'cosmic.snvindel.'+genome_v\n",
    "fusionFile = 'cosmic.fusion.'+genome_v\n",
    "if not os.path.isfile(snvindelFile):\n",
    "    print('Please run Part8 (step 7) to generate snvindel file!')\n",
    "    sys.exit(1)\n",
    "if not os.path.isfile(fusionFile):\n",
    "    print('Please run Part9 (step 8) to generate fusion file!')\n",
    "dbout = 'cosmic.'+genome_v+'.db'\n",
    "sqlFile = 'cosmic.'+genome_v+'.db.sql'\n",
    "!sqlite3 $dbout <$sqlFile\n",
    "if os.path.isfile(dbout):\n",
    "    print(dbout+' generated!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. <font color=blue>&nbsp;&nbsp;&nbsp;&nbsp;generate sliced db file</font> <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TP53    NM_000546 <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;KRAS    NM_033360<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NRAS    NM_002524<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FLT3    NM_004119 <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;BRAF    NM_004333<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ABL1    NM_005157 ABL1-BCR fusion （AML）<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CTNNB1  NM_001904 T41A<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FGFR1   NM_023110 N546K<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;H3-3A   NM_002107 K28M G35W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosmic.slice.hg19.db generated!\n"
     ]
    }
   ],
   "source": [
    "#check the snvindel file and fusion file\n",
    "import os\n",
    "import sys\n",
    "\n",
    "snvindelOutputFile = 'cosmic.snvindel.'+genome_v\n",
    "fusionOutFile = 'cosmic.fusion.'+genome_v\n",
    "if not os.path.isfile(snvindelOutputFile):\n",
    "    print('Please run step-11 to generate snvindel data!')\n",
    "    sys.exit(1)\n",
    "if not os.path.isfile(fusionOutFile):\n",
    "    print('Please run step-12 to generate fusion data!')\n",
    "    sys.exit(1)\n",
    "    \n",
    "slicedSnvindelFile = 'cosmic.snvindel.slice.'+genome_v\n",
    "slicedFusionFile = 'cosmic.fusion.slice.'+genome_v\n",
    "sliceddbout = 'cosmic.slice.'+genome_v+'.db'\n",
    "!printf \"NM_000546\\nNM_033360\\nNM_002524\\nNM_004119\\nNM_004333\\nNM_005157\\nNM_001904\\nNM_023110\\nNM_002107\\n\" >gene4sliceddb\n",
    "!grep -w -f gene4sliceddb $snvindelOutputFile > $slicedSnvindelFile\n",
    "!grep -w -f gene4sliceddb $fusionOutFile >$slicedFusionFile\n",
    "slicedsqlFile = 'cosmic.slice.'+genome_v+'.db.sql'\n",
    "!sqlite3 $sliceddbout <$slicedsqlFile\n",
    "if os.path.isfile(sliceddbout):\n",
    "    print(sliceddbout+' generated!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. <font color=blue>&nbsp;&nbsp;&nbsp;&nbsp;delete intermediate files</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CosmicMutantExport_GRCh38.tsv.gz.genomic.tab deleted!\n",
      "step1_hg38.elog deleted!\n",
      "step3_hg38.log deleted!\n",
      "CosmicMutantExport_GRCh38.tsv.gz.genomic.tab.exac.tab.cleaned.tab.hgvs.tab deleted!\n",
      "CosmicMutantExport_GRCh38.tsv.gz.genomic.tab.exac.tab.cleaned.tab deleted!\n",
      "step4-5_hg38.log deleted!\n",
      "CosmicCodingMuts_GRCh38.tsv.gz.cooked.tab deleted!\n",
      "step6_hg38.log deleted!\n",
      "step4-5_hg38.elog deleted!\n",
      "step6_hg38.elog deleted!\n",
      "CosmicMutantExport_GRCh38.tsv.gz.genomic.tab.exac.tab.cleaned.tab.hgvs.tab.unique.tab deleted!\n",
      "step4_hg38.log deleted!\n",
      "CosmicMutantExport_GRCh38.tsv.gz.genomic.tab.exac.tab deleted!\n",
      "step5_hg38.elog deleted!\n",
      "step5_hg38.log deleted!\n",
      "step1_hg38.log deleted!\n",
      "step2_hg38.log deleted!\n",
      "CosmicMutantExport_GRCh38.tsv.gz.genomic.tab.exac.tab.null_positions.tab deleted!\n",
      "step4_hg38.elog deleted!\n",
      "step3_hg38.elog deleted!\n",
      "step2_hg38.elog deleted!\n",
      "Congratulations!!! Legacy db building for hg38 is done!\n"
     ]
    }
   ],
   "source": [
    "#intermediate files deletion\n",
    "import os\n",
    "\n",
    "intermFiles = [x for x in os.listdir() if x.endswith('.tab') or x.endswith('log')]\n",
    "\n",
    "for f in intermFiles:\n",
    "    os.system('rm -f '+f)\n",
    "    print(f+' deleted!')\n",
    "print(\"Congratulations!!! Legacy db building for \"+genome_v+' is done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## script files (need to run each of the following cells first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting vcf_allele_ext_hg19.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile vcf_allele_ext_hg19.sh\n",
    "\n",
    "#!/bin/bash\n",
    "#BSUB -J VCF_Allele_ext_hg19\n",
    "#BSUB -q standard \n",
    "#BSUB -M 10000\n",
    "#BSUB -e vcf_allele_ext_hg19.elog\n",
    "#BSUB -o vcf_allele_ext_hg19.log\n",
    "\n",
    "\n",
    "vcf2tab.pl -file CosmicCodingMuts_GRCh37.tsv.gz -cosmic 2 -lite -filter-duplicates-strict 1 -duplicate-add-field COSMIC_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting vcf_allele_ext_hg38.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile vcf_allele_ext_hg38.sh\n",
    "\n",
    "#!/bin/bash\n",
    "#BSUB -J VCF_Allele_ext_hg38\n",
    "#BSUB -q standard \n",
    "#BSUB -M 10000\n",
    "#BSUB -e vcf_allele_ext_hg38.elog\n",
    "#BSUB -o vcf_allele_ext_hg38.log\n",
    "\n",
    "\n",
    "vcf2tab.pl -file CosmicCodingMuts_GRCh38.tsv.gz -cosmic 2 -lite -filter-duplicates-strict 1 -duplicate-add-field COSMIC_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting genoallel_anno_hg19.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile genoallel_anno_hg19.sh \n",
    "\n",
    "#!/bin/bash\n",
    "#BSUB -J genoallel_anno_hg19\n",
    "#BSUB -q standard \n",
    "#BSUB -M 10000\n",
    "#BSUB -e genoallel_anno_hg19.elog\n",
    "#BSUB -o genoallel_anno_hg19.log\n",
    "\n",
    "COSMIC_TAB=CosmicMutantExport_GRCh37.tsv.gz\n",
    "COSMIC_VCF_COOKED=CosmicCodingMuts_GRCh37.tsv.gz.cooked.tab\n",
    "cosmic_cleaner.pl -cosmic $COSMIC_TAB -vcf-allele-annotate $COSMIC_VCF_COOKED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting genoallel_anno_hg38.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile genoallel_anno_hg38.sh \n",
    "\n",
    "#!/bin/bash\n",
    "#BSUB -J genoallel_anno_hg38\n",
    "#BSUB -q standard \n",
    "#BSUB -M 10000\n",
    "#BSUB -e genoallel_anno_hg38.elog\n",
    "#BSUB -o genoallel_anno_hg38.log\n",
    "\n",
    "COSMIC_TAB=CosmicMutantExport_GRCh38.tsv.gz\n",
    "COSMIC_VCF_COOKED=CosmicCodingMuts_GRCh38.tsv.gz.cooked.tab\n",
    "cosmic_cleaner.pl -cosmic $COSMIC_TAB -vcf-allele-annotate $COSMIC_VCF_COOKED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting freqfilter_hg19.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile freqfilter_hg19.sh\n",
    "\n",
    "#!/bin/bash\n",
    "#BSUB -J freqfilter_hg19\n",
    "#BSUB -q standard \n",
    "#BSUB -e freqfilter_hg19.elog\n",
    "#BSUB -o freqfilter_hg19.log\n",
    "\n",
    "mux.pl -file CosmicMutantExport_GRCh37.tsv.gz.genomic.tab -template 'tag_exac.pl -genome GRCh37-lite -file %s -bambino -ignore-unusab\n",
    "le -no-annotation -require-af-le 0.001' -suffix exac.tab -count 100000 -ram 500 -wait 30 -clean glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting freqfilter_hg38.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile freqfilter_hg38.sh\n",
    "\n",
    "#!/bin/bash\n",
    "#BSUB -J freqfilter_hg38\n",
    "#BSUB -q standard \n",
    "#BSUB -e freqfilter_hg38.elog\n",
    "#BSUB -o freqfilter_hg38.log\n",
    "\n",
    "mux.pl -file CosmicMutantExport_GRCh38.tsv.gz.genomic.tab -template 'tag_exac.pl -genome GRCh38 -file %s -bambino -ignore-unusable -n\n",
    "o-annotation -require-af-le 0.001' -suffix exac.tab -count 100000 -ram 500 -wait 30 -clean glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cleaning_hg19.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile cleaning_hg19.sh\n",
    "\n",
    "#!/bin/bash\n",
    "#BSUB -J cleaning_hg19\n",
    "#BSUB -q standard\n",
    "#BSUB -M 20000\n",
    "#BSUB -e cleaning_hg19.elog\n",
    "#BSUB -o cleaning_hg19.log\n",
    "\n",
    "export CS_DIR=/rgs01/project_space/zhanggrp/ClinicalSeq/common\n",
    "export SUPPORT_DIR=$CS_DIR/germline_PublicDB/COSMIC/clean_support\n",
    "cosmic_cleaner.pl -cosmic CosmicMutantExport_GRCh37.tsv.gz.genomic.tab.exac.tab -genome GRCh37-lite -hypermutable-samples $CS_DIR/hypermutable_sample_0819_2013.lst -cancer-gene-list $CS_DIR/cancer_gene.lst -bad-gene-list $CS_DIR/bad_gene.lst -refgene-fasta $SUPPORT_DIR/human.rna.fna.gz -tolerant 1 -bad-literature $CS_DIR/bad_gene_literature.lst.mod -bad-variants $CS_DIR/bad_CHEK2_site.txt -no-summary -no-recurrence -gedi-validated $SUPPORT_DIR/gedi_validated.tab -out-suffix cleaned.tab $*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cleaning_hg38.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile cleaning_hg38.sh\n",
    "#!/bin/bash\n",
    "#BSUB -J cleaning_hg38\n",
    "#BSUB -q standard \n",
    "#BSUB -M 20000\n",
    "#BSUB -e cleaning_hg38.elog\n",
    "#BSUB -o cleaning_hg38.log\n",
    "\n",
    "export CS_DIR=/rgs01/project_space/zhanggrp/ClinicalSeq/common\n",
    "export SUPPORT_DIR=$CS_DIR/germline_PublicDB/COSMIC/clean_support\n",
    "cosmic_cleaner.pl -cosmic CosmicMutantExport_GRCh38.tsv.gz.genomic.tab.exac.tab -genome GRCh38 -hypermutable-samples $CS_DIR/hypermutable_sample_0819_2013.lst -cancer-gene-list $CS_DIR/cancer_gene.lst -bad-gene-list $CS_DIR/bad_gene.lst -refgene-fasta $SUPPORT_DIR/human.rna.fna.gz -tolerant 1 -bad-literature $CS_DIR/bad_gene_literature.lst.mod -bad-variants $CS_DIR/bad_CHEK2_site.txt -no-summary -no-recurrence -gedi-validated $SUPPORT_DIR/hg38/gedi_validated.tab.liftover.tab.edit -reannotate 2 -out-suffix cleaned.tab $*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing sorting_hg19.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile sorting_hg19.sh\n",
    "\n",
    "#!/bin/bash\n",
    "#BSUB -J sorting_hg19\n",
    "#BSUB -q standard\n",
    "#BSUB -M 30000\n",
    "#BSUB -e sorting_hg19.elog\n",
    "#BSUB -o sorting_hg19.log\n",
    "\n",
    "head -n 1 CosmicMutantExport_GRCh37.tsv.gz.genomic.tab.exac.tab.cleaned.tab >CosmicMutantExport_GRCh37.tsv.gz.genomic.tab.exac.tab.cleaned.tab.sorted\n",
    "tail -n +2 CosmicMutantExport_GRCh37.tsv.gz.genomic.tab.exac.tab.cleaned.tab >x.hg19\n",
    "cut -f38,39 x.hg19 >y.hg19 #check if the chromosome and position are always on 38th and 39th coloumns\n",
    "paste y.hghg19 x.hg19 >z.hg19\n",
    "sort -k1,1 -k2,2n z.hg19 >z.hg19.sorted\n",
    "cut -f 3- z.hg19.sorted >>CosmicMutantExport_GRCh37.tsv.gz.genomic.tab.exac.tab.cleaned.tab.sorted\n",
    "rm -f x.hg19 y.hg19 z.hg19 z.hg19.sorted\n",
    "mv CosmicMutantExport_GRCh37.tsv.gz.genomic.tab.exac.tab.cleaned.tab.sorted CosmicMutantExport_GRCh37.tsv.gz.genomic.tab.exac.tab.cleaned.tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing sorting_hg38.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile sorting_hg38.sh\n",
    "\n",
    "#!/bin/bash\n",
    "#BSUB -J sorting_hg38\n",
    "#BSUB -q standard\n",
    "#BSUB -M 30000\n",
    "#BSUB -e sorting_hg38.elog\n",
    "#BSUB -o sorting_hg38.log\n",
    "\n",
    "head -n 1 CosmicMutantExport_GRCh38.tsv.gz.genomic.tab.exac.tab.cleaned.tab >CosmicMutantExport_GRCh38.tsv.gz.genomic.tab.exac.tab.cleaned.tab.sorted\n",
    "tail -n +2 CosmicMutantExport_GRCh38.tsv.gz.genomic.tab.exac.tab.cleaned.tab >x.hg38\n",
    "cut -f38,39 x.hg38 >y.hg38 #check if the chromosome and position are always on 38th and 39th coloumns\n",
    "paste y.hg38 x.hg38 >z.hg38\n",
    "sort -k1,1 -k2,2n z.hg38 >z.hg38.sorted\n",
    "cut -f 3- z.hg38.sorted >>CosmicMutantExport_GRCh38.tsv.gz.genomic.tab.exac.tab.cleaned.tab.sorted\n",
    "rm -f x.hg38 y.hg38 z.hg38 z.hg38.sorted\n",
    "mv CosmicMutantExport_GRCh38.tsv.gz.genomic.tab.exac.tab.cleaned.tab.sorted CosmicMutantExport_GRCh38.tsv.gz.genomic.tab.exac.tab.cleaned.tab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing vep_hg19.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile vep_hg19.sh\n",
    "\n",
    "#!/bin/bash\n",
    "#BSUB -J vep_hg19\n",
    "#BSUB -q standard\n",
    "#BSUB -e vep_hg19.elog\n",
    "#BSUB -o vep_hg19.log\n",
    "\n",
    "GENOME=GRCh37-lite\n",
    "mux.pl -file CosmicMutantExport_GRCh37.tsv.gz.genomic.tab.exac.tab.cleaned.tab -ram 2250 -suffix hgvs.tab -wait 30 -clean glob -pool 400 -count 10000 -bsub-cores 2 -template \"bambino2vep.pl -file %s -genome $GENOME -bambino\" $*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing vep_hg38.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile vep_hg38.sh\n",
    "\n",
    "#!/bin/bash\n",
    "#BSUB -J vep_hg38\n",
    "#BSUB -q standard\n",
    "#BSUB -e vep_hg38.elog\n",
    "#BSUB -o vep_hg38.log\n",
    "\n",
    "GENOME=GRCh38\n",
    "mux.pl -file CosmicMutantExport_GRCh38.tsv.gz.genomic.tab.exac.tab.cleaned.tab -ram 2250 -suffix hgvs.tab -wait 30 -clean glob -pool 400 -count 10000 -bsub-cores 2 -template \"bambino2vep.pl -file %s -genome $GENOME -bambino\" $*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing duprm_hg19.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile duprm_hg19.sh\n",
    "\n",
    "#!/bin/bash\n",
    "#BSUB -J duprm_hg19\n",
    "#BSUB -q standard\n",
    "#BSUB -M 10000\n",
    "#BSUB -e duprm_hg19.elog\n",
    "#BSUB -o duprm_hg19.log\n",
    "\n",
    "bambino2annovar.pl -filter-sample-duplicates -f-sample ID_sample -f-gene vep_sj_gene -f-aa vep_sj_aachange -file CosmicMutantExport_GRCh37.tsv.gz.genomic.tab.exac.tab.cleaned.tab.hgvs.tab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing duprm_hg38.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile duprm_hg38.sh\n",
    "\n",
    "#!/bin/bash\n",
    "#BSUB -J duprm_hg38\n",
    "#BSUB -q standard\n",
    "#BSUB -M 10000\n",
    "#BSUB -e duprm_hg38.elog\n",
    "#BSUB -o duprm_hg38.log\n",
    "\n",
    "bambino2annovar.pl -filter-sample-duplicates -f-sample ID_sample -f-gene vep_sj_gene -f-aa vep_sj_aachange -file CosmicMutantExport_GRCh38.tsv.gz.genomic.tab.exac.tab.cleaned.tab.hgvs.tab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting gencosmicsnvindel.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile gencosmicsnvindel.py\n",
    "\n",
    "#!/usr/bin/python3\n",
    "\n",
    "#generate file for db file building\n",
    "\n",
    "import sys\n",
    "\n",
    "if len(sys.argv) < 3:\n",
    "        print('usage: python3 '+sys.argv[1]+' <*.tab.cleaned.tab.hgvs.tab.unique.tab> <output>')\n",
    "        sys.exit(1)\n",
    "\n",
    "header = ['Gene name', 'Accession Number', 'Gene CDS length', 'HGNC ID', 'Sample name', 'ID_sample', 'ID_tumour', 'Primary site', 'Site subtype 1', 'Site subtype 2', 'Site subtype 3', 'Primary histology', 'Histology subtype 1', 'Histology subtype 2', 'Histology subtype 3', 'Genome-wide screen', 'GENOMIC_MUTATION_ID', 'LEGACY_MUTATION_ID', 'MUTATION_ID', 'Mutation CDS', 'Mutation AA', 'Mutation Description', 'Mutation zygosity', 'LOH', 'GRCh', 'Mutation genome position', 'Mutation strand', 'Resistance Mutation', 'Mutation somatic status', 'Pubmed_PMID', 'ID_STUDY', 'Sample Type', 'Tumour origin', 'Age', 'HGVSP', 'HGVSC', 'HGVSG', 'Chr', 'Pos', 'Chr_Allele', 'Alternative_Allele', 'sj_diagnosis', 'sj_subtype', 'sj_subgroup', 'Gene', 'Feature', 'Feature_type', 'Consequence', 'cDNA_position', 'CDS_position', 'Protein_position', 'Amino_acids', 'Codons', 'Existing_variation', 'Extra', 'vep_HGVSp', 'vep_HGVSc', 'vep_sj_gene', 'vep_sj_class', 'vep_sj_aachange', 'vep_sj_cdna', 'vep_pubmed', 'vep_sj_note', 'vep_sj_filter_isoform', 'vep_sj_filter_isoform_unversioned', 'vep_sj_filter_isoform_preferred', 'vep_result_count']\n",
    "\n",
    "inputfile = sys.argv[1]\n",
    "fh = open(inputfile)\n",
    "out = open(sys.argv[2],'w')\n",
    "fileheader = fh.readline().strip().split('\\t')\n",
    "if not fileheader == header:\n",
    "        print('please check the file header:')\n",
    "        print('the header should be in the order:')\n",
    "        for e in header:\n",
    "                print(e)\n",
    "        sys.exit(1)\n",
    "for line in fh:\n",
    "        l = line.replace('\\n','').split('\\t')\n",
    "        OUTL = l[0:27]\n",
    "        OUTL.append('') # no snp info from VEP+ pipeline\n",
    "        OUTL.append(l[27])\n",
    "        OUTL.extend(['']*2) # no fathmm_prediction and fathmm_score\n",
    "        OUTL.extend(l[28:34])\n",
    "        OUTL.extend(l[41:44]) # sj_diagnosis, subtype, subgroup\n",
    "        #OUTL.extend(l[34:37]) # sj_diagnosis, subtype, subgroup\n",
    "        OUTL.extend(l[37:41]) # chr, pos, ref, alt\n",
    "        OUTL.extend(['']*3) # no genomic_parsable, type and notes\n",
    "        #OUTL.extend(l[41:44]) # no genomic_parsable, type and notes\n",
    "        OUTL.append('') #no annovar_region \n",
    "        OUTL.append(l[57])\n",
    "        OUTL.extend(['']*2) # no annovar_exonic_function and annovar_exonic_function_gene\n",
    "        OUTL.append(l[57])\n",
    "        OUTL.append(l[44]) #gi\n",
    "        OUTL.extend(l[58:61]) # class, aachange,cdna\n",
    "        OUTL.append('') # no exception\n",
    "        OUTL.append(l[62]) #note\n",
    "        if '.' in l[63]:\n",
    "                ISO = l[63].split('.')[0]\n",
    "        else:\n",
    "                ISO = l[63]\n",
    "        OUTL.extend([ISO,l[65]])\n",
    "        out.write('\\t'.join(OUTL)+'\\n')\n",
    "fh.close()\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cosmic_fusion.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile cosmic_fusion.py \n",
    "\n",
    "#!/usr/bin/python3\n",
    "\n",
    "import sys\n",
    "import gzip\n",
    "import json\n",
    "import re\n",
    "\n",
    "if len(sys.argv) == 1:\n",
    "        print('Usage: python3 '+sys.argv[0]+' <CosmicfusionExport_GRCh37.tsv.gz> <hg19/hg38> <output>')\n",
    "        sys.exit(1)\n",
    "#####\n",
    "#function\n",
    "def FINDTRANSID(fusionName):\n",
    "        searchRT = re.search('.*?(ENST.*?)\\..*?(ENST.*?)\\.',fusionName)\n",
    "        if not searchRT:\n",
    "                return False\n",
    "        ENSIDS = searchRT.groups()\n",
    "        if len(ENSIDS) != 2:\n",
    "                return False\n",
    "        else:\n",
    "                return ENSIDS\n",
    "def PARSEJS(breakpoints):\n",
    "        chra,stda,ga,posastart,posastop,chrb,stdb,gb,posbstart,posbstop = breakpoints\n",
    "        ajs = {}\n",
    "        bjs = {}\n",
    "        chra = chra.lower() if chra.lower().startswith('chr') else 'chr'+chra\n",
    "        ajs['chr'] = chra\n",
    "        chrb = chrb.lower() if chrb.lower().startswith('chr') else 'chr'+chrb\n",
    "        bjs['chr'] = chrb\n",
    "        ga = ga.strip().split('_')[0] if '_' in ga else ga\n",
    "        if ga:\n",
    "                ajs['name'] = ga\n",
    "        else:\n",
    "                print('no gene name: '+'\\t'.join(breakpoints))\n",
    "                sys.exit(1)\n",
    "        gb = gb.strip().split('_')[0] if '_' in gb else gb\n",
    "        if gb:\n",
    "                bjs['name'] = gb\n",
    "        else:\n",
    "                print('no gene name: '+'\\t'.join(breakpoints))\n",
    "                sys.exit(1)\n",
    "        ajs['strand'] = stda\n",
    "        bjs['strand'] = stdb\n",
    "        if stda == '+':\n",
    "                ajs['position'] = int(posastop) - 1\n",
    "        elif stda == '-':\n",
    "                ajs['position'] = int(posastart) - 1\n",
    "        if stdb == '+':\n",
    "                bjs['position'] = int(posbstart) - 1\n",
    "        elif stdb == '-':\n",
    "                bjs['position'] = int(posbstop) - 1\n",
    "        return ajs,bjs\n",
    "\n",
    "rawfile = sys.argv[1]\n",
    "genomename = sys.argv[2]\n",
    "out = open(sys.argv[3],'w')\n",
    "builds = {\n",
    "        'hg19':{\n",
    "                'ref2ens':'/research/rgs01/resgen/legacy/gb_customTracks/tp/jwang/tools/cosmic_update/dataset/hg19/wgEncodeGencodeRefSeqV34lift37.txt'\n",
    "        },\n",
    "        'hg38':{\n",
    "                'ref2ens':'/research/rgs01/resgen/legacy/gb_customTracks/tp/jwang/tools/cosmic_update/dataset/hg38/wgEncodeGencodeRefSeqV34.txt'\n",
    "        }\n",
    "}\n",
    "\n",
    "genome = builds[genomename]\n",
    "refseqmap={}\n",
    "for line in open(genome['ref2ens']):\n",
    "        l = line.strip().split('\\t')\n",
    "        if l[0] and l[1]:\n",
    "                refseqmap[l[0].split('.')[0]] = l[1].split('.')[0]\n",
    "\n",
    "\n",
    "sample2fus={}\n",
    "JSINFO = [\"5'_CHROMOSOME\",\"5'_STRAND\",\"5'_GENE_NAME\",\"5'_GENOME_START_FROM\",\"5'_GENOME_STOP_FROM\",\"3'_CHROMOSOME\",\"3'_STRAND\",\"3'_GENE_NAME\",\"3'_GENOME_START_FROM\",\"3'_GENOME_STOP_FROM\"]\n",
    "extInfo = ['PRIMARY_SITE','SITE_SUBTYPE_1','SITE_SUBTYPE_2','SITE_SUBTYPE_3','PRIMARY_HISTOLOGY','HISTOLOGY_SUBTYPE_1','HISTOLOGY_SUBTYPE_2','HISTOLOGY_SUBTYPE_3','FUSION_TYPE','PUBMED_PMID']\n",
    "\n",
    "\n",
    "fh = gzip.open(rawfile)\n",
    "head = fh.readline().decode('utf-8').strip().split('\\t')\n",
    "headidx = {x:head.index(x) for x in head}\n",
    "\n",
    "nofusionname = 0\n",
    "skipquestionmark = 0\n",
    "norefseq_nomatchensemble = 0\n",
    "nopairtransid = 0\n",
    "nobreakpointinfo = 0\n",
    "duplicated = 0\n",
    "\n",
    "for line in fh:\n",
    "        l = line.decode('utf-8').replace('\\n','').split('\\t')\n",
    "        if not 'TRANSLOCATION_NAME' in head:\n",
    "                print('Check header: there is no the column TRANSLOCATION_NAME')\n",
    "                sys.exit(1)\n",
    "        sampleID = l[headidx['SAMPLE_ID']]\n",
    "        sampleName = l[headidx['SAMPLE_NAME']]\n",
    "        fus = l[headidx['TRANSLOCATION_NAME']]\n",
    "        if not fus:\n",
    "                nofusionname += 1\n",
    "                continue\n",
    "        if '?' in fus:\n",
    "                skipquestionmark += 1\n",
    "                continue\n",
    "        transcript_id = FINDTRANSID(fus)\n",
    "        if not transcript_id:\n",
    "                nopairtransid += 1\n",
    "                continue\n",
    "        else:\n",
    "                id1,id2 = transcript_id\n",
    "        if not sampleID in sample2fus:\n",
    "                sample2fus[sampleID] = {}\n",
    "        if not fus in sample2fus[sampleID]:\n",
    "                sample2fus[sampleID][fus] = 1\n",
    "        else:\n",
    "                duplicated += 1\n",
    "                continue\n",
    "        refid1 = refseqmap[id1] if id1 in refseqmap else False\n",
    "        refid2 = refseqmap[id2] if id2 in refseqmap else False\n",
    "        if not refid1 or not refid2:\n",
    "                norefseq_nomatchensemble += 1\n",
    "                continue\n",
    "        #json info\n",
    "        breakpointinfo = [l[headidx[x]] for x in JSINFO]\n",
    "        if not all(breakpointinfo):\n",
    "                nobreakpointinfo += 1\n",
    "                continue\n",
    "        ajs,bjs = PARSEJS([l[headidx[x]] for x in JSINFO])\n",
    "        ajs['isoform'] = refid1\n",
    "        bjs['isoform'] = refid2\n",
    "        JS = [{'a':ajs,'b':bjs,'translocationname':fus}]\n",
    "        name = '.'.join([ajs['name'],bjs['name']])\n",
    "        iso = '.'.join([refid1,refid2])\n",
    "        out.write('\\t'.join([sampleID,sampleName,name,iso,json.dumps(JS,sort_keys=True)]+[l[headidx[x]] for x in extInfo])+'\\n')\n",
    "fh.close()\n",
    "out.close()\n",
    "\n",
    "if nofusionname:\n",
    "        print(str(nofusionname)+' lines have no fusion name')\n",
    "if norefseq_nomatchensemble:\n",
    "         print(str(norefseq_nomatchensemble)+' lines with ensemble name cannot be converted to refseq')\n",
    "if nopairtransid:\n",
    "        print(str(nopairtransid)+' lines have not paired transcript ID')\n",
    "if duplicated:\n",
    "        print(str(duplicated)+' duplicated lines removed')\n",
    "if nobreakpointinfo:\n",
    "        print(str(nobreakpointinfo)+' skipped for lines without breakpoint info')\n",
    "if skipquestionmark:\n",
    "        print(str(skipquestionmark)+' skipped for ? in fusion name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cosmic.hg19.db.sql\n"
     ]
    }
   ],
   "source": [
    "%%writefile cosmic.hg19.db.sql\n",
    "\n",
    "drop table if exists cosmic_hg19;\n",
    "create table cosmic_hg19 (\n",
    "gene1 character varying(100) null,\n",
    "gene1accession character varying(100) null,\n",
    "gene1cdslen integer null,\n",
    "hgnc_id integer null,\n",
    "sample_name character varying(255),\n",
    "id_sample integer,\n",
    "id_tumor integer,\n",
    "primary_site character varying(255),\n",
    "site_subtype1 character varying(255),\n",
    "site_subtype2 character varying(255),\n",
    "site_subtype3 character varying(255),\n",
    "primary_histology character varying(255),\n",
    "histology_subtype1 character varying(255),\n",
    "histology_subtype2 character varying(255),\n",
    "histology_subtype3 character varying(255),\n",
    "genome_wide_screen character varying(255),\n",
    "genomic_mutation_id character varying(255),\n",
    "legacy_mutation_id character varying(255),\n",
    "mutation_id character varying(255),\n",
    "mutation_cds character varying(255),\n",
    "mutation_aa character varying(255),\n",
    "mutation_description character varying(255),\n",
    "mutation_zygosity character varying(255),\n",
    "loh character varying(255),\n",
    "grch integer,\n",
    "genome_coordinate character varying(255),\n",
    "strand character(1),\n",
    "snp character varying(10),\n",
    "resistance_mutation character varying(10),\n",
    "fathmm_prediction character varying(255),\n",
    "fathmm_score character varying(255),\n",
    "mutation_somatic_status character varying(255),\n",
    "pmid integer,\n",
    "id_study integer,\n",
    "sample_source character varying(255),\n",
    "tumor_origin character varying(255),\n",
    "age character varying(255),\n",
    "sj_diagnosis character varying(255),\n",
    "sj_subtype character varying(255),\n",
    "sj_subgroup     character varying(255),\n",
    "chr character(2),\n",
    "position integer,\n",
    "reference_allele character varying(255),\n",
    "mutant_allele character varying(255),\n",
    "genomic_parsable character(1),\n",
    "genomic_parsable_type character varying(255),\n",
    "genomic_parsable_notes character varying(255),\n",
    "annovar_region character varying(255),\n",
    "annovar_region_gene     character varying(255),\n",
    "annovar_exonic_function character varying(255),\n",
    "annovar_exonic_function_gene character varying(255),\n",
    "annovar_sj_gene character varying(255),\n",
    "annovar_sj_gi integer,\n",
    "annovar_sj_class character varying(255),\n",
    "annovar_sj_aachange character varying(255),\n",
    "annovar_sj_cdna character varying(255),\n",
    "annovar_sj_exception character varying(255),\n",
    "annovar_sj_notecharacter varying(255),\n",
    "annovar_sj_filter_isoform character varying(255),\n",
    "annovar_sj_filter_isoform_preferred     character(1)\n",
    ");\n",
    "\n",
    "drop table if exists cosmic_fusion;\n",
    "create table cosmic_fusion (\n",
    "sample_id int,\n",
    "sample_name character varying(255),\n",
    "genes text,\n",
    "isoforms text,\n",
    "fusions json,\n",
    "primarysite character,\n",
    "sitesubtype1 character,\n",
    "sitesubtype2 character,\n",
    "sitesubtype3 character,\n",
    "primaryhistology character,\n",
    "histologysubtype1 character,\n",
    "histologysubtype2 character,\n",
    "histologysubtype3 character,\n",
    "note character,\n",
    "pmid integer\n",
    ");\n",
    "\n",
    ".mode tabs\n",
    ".import cosmic.fusion.hg19 cosmic_fusion\n",
    ".import cosmic.snvindel.hg19 cosmic_hg19\n",
    "\n",
    "\n",
    "create index cosmic_hg19_refseq on cosmic_hg19(annovar_sj_filter_isoform);\n",
    "create index cosmicfusiongene on cosmic_fusion(genes);\n",
    "create index cosmicfusionisoform on cosmic_fusion(isoforms);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cosmic.slice.hg19.db.sql\n"
     ]
    }
   ],
   "source": [
    "%%writefile cosmic.slice.hg19.db.sql\n",
    "\n",
    "drop table if exists cosmic_hg19;\n",
    "create table cosmic_hg19 (\n",
    "gene1 character varying(100) null,\n",
    "gene1accession character varying(100) null,\n",
    "gene1cdslen integer null,\n",
    "hgnc_id integer null,\n",
    "sample_name character varying(255),\n",
    "id_sample integer,\n",
    "id_tumor integer,\n",
    "primary_site character varying(255),\n",
    "site_subtype1 character varying(255),\n",
    "site_subtype2 character varying(255),\n",
    "site_subtype3 character varying(255),\n",
    "primary_histology character varying(255),\n",
    "histology_subtype1 character varying(255),\n",
    "histology_subtype2 character varying(255),\n",
    "histology_subtype3 character varying(255),\n",
    "genome_wide_screen character varying(255),\n",
    "genomic_mutation_id character varying(255),\n",
    "legacy_mutation_id character varying(255),\n",
    "mutation_id character varying(255),\n",
    "mutation_cds character varying(255),\n",
    "mutation_aa character varying(255),\n",
    "mutation_description character varying(255),\n",
    "mutation_zygosity character varying(255),\n",
    "loh character varying(255),\n",
    "grch integer,\n",
    "genome_coordinate character varying(255),\n",
    "strand character(1),\n",
    "snp character varying(10),\n",
    "resistance_mutation character varying(10),\n",
    "fathmm_prediction character varying(255),\n",
    "fathmm_score character varying(255),\n",
    "mutation_somatic_status character varying(255),\n",
    "pmid integer,\n",
    "id_study integer,\n",
    "sample_source character varying(255),\n",
    "tumor_origin character varying(255),\n",
    "age character varying(255),\n",
    "sj_diagnosis character varying(255),\n",
    "sj_subtype character varying(255),\n",
    "sj_subgroup     character varying(255),\n",
    "chr character(2),\n",
    "position integer,\n",
    "reference_allele character varying(255),\n",
    "mutant_allele character varying(255),\n",
    "genomic_parsable character(1),\n",
    "genomic_parsable_type character varying(255),\n",
    "genomic_parsable_notes character varying(255),\n",
    "annovar_region character varying(255),\n",
    "annovar_region_gene     character varying(255),\n",
    "annovar_exonic_function character varying(255),\n",
    "annovar_exonic_function_gene character varying(255),\n",
    "annovar_sj_gene character varying(255),\n",
    "annovar_sj_gi integer,\n",
    "annovar_sj_class character varying(255),\n",
    "annovar_sj_aachange character varying(255),\n",
    "annovar_sj_cdna character varying(255),\n",
    "annovar_sj_exception character varying(255),\n",
    "annovar_sj_notecharacter varying(255),\n",
    "annovar_sj_filter_isoform character varying(255),\n",
    "annovar_sj_filter_isoform_preferred     character(1)\n",
    ");\n",
    "\n",
    "drop table if exists cosmic_fusion;\n",
    "create table cosmic_fusion (\n",
    "sample_id int,\n",
    "sample_name character varying(255),\n",
    "genes text,\n",
    "isoforms text,\n",
    "fusions json,\n",
    "primarysite character,\n",
    "sitesubtype1 character,\n",
    "sitesubtype2 character,\n",
    "sitesubtype3 character,\n",
    "primaryhistology character,\n",
    "histologysubtype1 character,\n",
    "histologysubtype2 character,\n",
    "histologysubtype3 character,\n",
    "note character,\n",
    "pmid integer\n",
    ");\n",
    "\n",
    ".mode tabs\n",
    ".import cosmic.fusion.slice.hg19 cosmic_fusion\n",
    ".import cosmic.snvindel.slice.hg19 cosmic_hg19\n",
    "\n",
    "\n",
    "create index cosmic_hg19_refseq on cosmic_hg19(annovar_sj_filter_isoform);\n",
    "create index cosmicfusiongene on cosmic_fusion(genes);\n",
    "create index cosmicfusionisoform on cosmic_fusion(isoforms);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cosmic.hg38.db.sql\n"
     ]
    }
   ],
   "source": [
    "%%writefile cosmic.hg38.db.sql\n",
    "\n",
    "drop table if exists cosmic;\n",
    "create table cosmic (\n",
    "gene1 character varying(100) null,\n",
    "gene1accession character varying(100) null,\n",
    "gene1cdslen integer null,\n",
    "hgnc_id integer null,\n",
    "sample_name character varying(255),\n",
    "id_sample integer,\n",
    "id_tumor integer,\n",
    "primary_site character varying(255),\n",
    "site_subtype1 character varying(255),\n",
    "site_subtype2 character varying(255),\n",
    "site_subtype3 character varying(255),\n",
    "primary_histology character varying(255),\n",
    "histology_subtype1 character varying(255),\n",
    "histology_subtype2 character varying(255),\n",
    "histology_subtype3 character varying(255),\n",
    "genome_wide_screen character varying(255),\n",
    "genomic_mutation_id character varying(255),\n",
    "legacy_mutation_id character varying(255),\n",
    "mutation_id character varying(255),\n",
    "mutation_cds character varying(255),\n",
    "mutation_aa character varying(255),\n",
    "mutation_description character varying(255),\n",
    "mutation_zygosity character varying(255),\n",
    "loh character varying(255),\n",
    "grch integer,\n",
    "genome_coordinate character varying(255),\n",
    "strand character(1),\n",
    "snp character varying(10),\n",
    "resistance_mutation character varying(10),\n",
    "fathmm_prediction character varying(255),\n",
    "fathmm_score character varying(255),\n",
    "mutation_somatic_status character varying(255),\n",
    "pmid integer,\n",
    "id_study integer,\n",
    "sample_source character varying(255),\n",
    "tumor_origin character varying(255),\n",
    "age character varying(255),\n",
    "sj_diagnosis character varying(255),\n",
    "sj_subtype character varying(255),\n",
    "sj_subgroup\tcharacter varying(255),\n",
    "chr character(2),\n",
    "position integer,\n",
    "reference_allele character varying(255),\n",
    "mutant_allele character varying(255),\n",
    "genomic_parsable character(1),\n",
    "genomic_parsable_type character varying(255),\n",
    "genomic_parsable_notes character varying(255),\n",
    "annovar_region character varying(255),\n",
    "annovar_region_gene\tcharacter varying(255),\n",
    "annovar_exonic_function character varying(255),\n",
    "annovar_exonic_function_gene character varying(255),\n",
    "annovar_sj_gene character varying(255),\n",
    "annovar_sj_gi integer,\n",
    "annovar_sj_class character varying(255),\n",
    "annovar_sj_aachange character varying(255),\n",
    "annovar_sj_cdna character varying(255),\n",
    "annovar_sj_exception character varying(255),\n",
    "annovar_sj_notecharacter varying(255),\n",
    "annovar_sj_filter_isoform character varying(255),\n",
    "annovar_sj_filter_isoform_preferred\tcharacter(1)\n",
    ");\n",
    "\n",
    "drop table if exists cosmic_fusion;\n",
    "create table cosmic_fusion (\n",
    "sample_id int,\n",
    "sample_name character varying(255),\n",
    "genes text,\n",
    "isoforms text,\n",
    "fusions json,\n",
    "primarysite character,\n",
    "sitesubtype1 character,\n",
    "sitesubtype2 character,\n",
    "sitesubtype3 character,\n",
    "primaryhistology character,\n",
    "histologysubtype1 character,\n",
    "histologysubtype2 character,\n",
    "histologysubtype3 character,\n",
    "note character,\n",
    "pmid integer\n",
    ");\n",
    "\n",
    ".mode tabs\n",
    ".import cosmic.fusion.hg38 cosmic_fusion\n",
    ".import cosmic.snvindel.hg38 cosmic\n",
    "\n",
    "\n",
    "create index cosmic_refseq on cosmic(annovar_sj_filter_isoform);\n",
    "create index cosmicfusiongene on cosmic_fusion(genes);\n",
    "create index cosmicfusionisoform on cosmic_fusion(isoforms);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cosmic.slice.hg38.db.sql\n"
     ]
    }
   ],
   "source": [
    "%%writefile cosmic.slice.hg38.db.sql\n",
    "\n",
    "drop table if exists cosmic;\n",
    "create table cosmic (\n",
    "gene1 character varying(100) null,\n",
    "gene1accession character varying(100) null,\n",
    "gene1cdslen integer null,\n",
    "hgnc_id integer null,\n",
    "sample_name character varying(255),\n",
    "id_sample integer,\n",
    "id_tumor integer,\n",
    "primary_site character varying(255),\n",
    "site_subtype1 character varying(255),\n",
    "site_subtype2 character varying(255),\n",
    "site_subtype3 character varying(255),\n",
    "primary_histology character varying(255),\n",
    "histology_subtype1 character varying(255),\n",
    "histology_subtype2 character varying(255),\n",
    "histology_subtype3 character varying(255),\n",
    "genome_wide_screen character varying(255),\n",
    "genomic_mutation_id character varying(255),\n",
    "legacy_mutation_id character varying(255),\n",
    "mutation_id character varying(255),\n",
    "mutation_cds character varying(255),\n",
    "mutation_aa character varying(255),\n",
    "mutation_description character varying(255),\n",
    "mutation_zygosity character varying(255),\n",
    "loh character varying(255),\n",
    "grch integer,\n",
    "genome_coordinate character varying(255),\n",
    "strand character(1),\n",
    "snp character varying(10),\n",
    "resistance_mutation character varying(10),\n",
    "fathmm_prediction character varying(255),\n",
    "fathmm_score character varying(255),\n",
    "mutation_somatic_status character varying(255),\n",
    "pmid integer,\n",
    "id_study integer,\n",
    "sample_source character varying(255),\n",
    "tumor_origin character varying(255),\n",
    "age character varying(255),\n",
    "sj_diagnosis character varying(255),\n",
    "sj_subtype character varying(255),\n",
    "sj_subgroup\tcharacter varying(255),\n",
    "chr character(2),\n",
    "position integer,\n",
    "reference_allele character varying(255),\n",
    "mutant_allele character varying(255),\n",
    "genomic_parsable character(1),\n",
    "genomic_parsable_type character varying(255),\n",
    "genomic_parsable_notes character varying(255),\n",
    "annovar_region character varying(255),\n",
    "annovar_region_gene\tcharacter varying(255),\n",
    "annovar_exonic_function character varying(255),\n",
    "annovar_exonic_function_gene character varying(255),\n",
    "annovar_sj_gene character varying(255),\n",
    "annovar_sj_gi integer,\n",
    "annovar_sj_class character varying(255),\n",
    "annovar_sj_aachange character varying(255),\n",
    "annovar_sj_cdna character varying(255),\n",
    "annovar_sj_exception character varying(255),\n",
    "annovar_sj_notecharacter varying(255),\n",
    "annovar_sj_filter_isoform character varying(255),\n",
    "annovar_sj_filter_isoform_preferred\tcharacter(1)\n",
    ");\n",
    "\n",
    "drop table if exists cosmic_fusion;\n",
    "create table cosmic_fusion (\n",
    "sample_id int,\n",
    "sample_name character varying(255),\n",
    "genes text,\n",
    "isoforms text,\n",
    "fusions json,\n",
    "primarysite character,\n",
    "sitesubtype1 character,\n",
    "sitesubtype2 character,\n",
    "sitesubtype3 character,\n",
    "primaryhistology character,\n",
    "histologysubtype1 character,\n",
    "histologysubtype2 character,\n",
    "histologysubtype3 character,\n",
    "note character,\n",
    "pmid integer\n",
    ");\n",
    "\n",
    ".mode tabs\n",
    ".import cosmic.fusion.slice.hg38 cosmic_fusion\n",
    ".import cosmic.snvindel.slice.hg38 cosmic\n",
    "\n",
    "\n",
    "create index cosmic_refseq on cosmic(annovar_sj_filter_isoform);\n",
    "create index cosmicfusiongene on cosmic_fusion(genes);\n",
    "create index cosmicfusionisoform on cosmic_fusion(isoforms);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
